{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea10ecaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import needed packages\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import load_model\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a905005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to process image that need to be learn by the model in order to hit a higher accuracy for the model\n",
    "def process_img(image):\n",
    "    # Preprocess image into a PyTorch tensor\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    input_image = transform(image)\n",
    "    \n",
    "    # Load the pre-trained model Mask R-CNN model with a ResNet-50 backbone and FPN(Feature Pyramid Network)\n",
    "    model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    \n",
    "    # Disable the gradient computation and use the model to predict the input image\n",
    "    with torch.no_grad():\n",
    "        predictions = model([input_image])\n",
    "    \n",
    "    # Extract the masks and boxes from the prediction and return them as a numpy array\n",
    "    masks = predictions[0]['masks'].cpu().numpy()\n",
    "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
    "\n",
    "    # Calculate the areas of the boxes\n",
    "    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "    \n",
    "    # Find the index of largest value in the areas and use boxes to select the largest area using the index found\n",
    "    main_object_index = np.argmax(areas)\n",
    "    main_object_box = boxes[main_object_index]\n",
    "\n",
    "    # Convert the box coordinates to integers\n",
    "    main_object_box = main_object_box.astype(int)\n",
    "\n",
    "    # Extract the coordinates of the box\n",
    "    x, y, w, h = main_object_box\n",
    "\n",
    "    # Create a binary mask for the main object\n",
    "    main_object_mask = masks[main_object_index, 0] > 0.5\n",
    "\n",
    "    # Apply the binary mask to the input image\n",
    "    result = cv2.bitwise_and(image, image, mask=main_object_mask.astype(np.uint8))\n",
    "\n",
    "    # Create a background with transparent \n",
    "    transparent_background = np.zeros_like(image)\n",
    "\n",
    "    # Replace the object background as transparent \n",
    "    result[np.where(main_object_mask == 0)] = transparent_background[np.where(main_object_mask == 0)]\n",
    "\n",
    "    # Convert the result from BGR into BGRA format to make sure that the background is transparent\n",
    "    result_with_transparency = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "    result_with_transparency[np.where((result == [0, 0, 0]).all(axis=2))] = [0, 0, 0, 0]\n",
    "\n",
    "    # Find the contours of the object\n",
    "    contours, _ = cv2.findContours(main_object_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the minimum area rectangle around the contours and convert to integer\n",
    "    rect = cv2.minAreaRect(contours[0])\n",
    "    box = cv2.boxPoints(rect).astype(np.int32)\n",
    "\n",
    "    # Crop the image using the box\n",
    "    x, y, w, h = cv2.boundingRect(box)\n",
    "    cropped_image = result_with_transparency[y:y+h, x:x+w]\n",
    "    \n",
    "    # Return a cropped image\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd68a679",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to take an amount of frame from a video\n",
    "def take_frame(video):\n",
    "    # Set the output directory and create a new directory in the os\n",
    "    output_directory = f'{video}_img'\n",
    "    os.mkdir(output_directory)\n",
    "    \n",
    "    # Open the video and compute how many FPS(Frame Per Second) of video being process\n",
    "    open_video = cv2.VideoCapture(video)\n",
    "    frame = int(open_video.get(cv2.CAP_PROP_FPS))\n",
    "    \n",
    "    # Set the variable frame_count and x to zero and one\n",
    "    frame_count = 0\n",
    "    x = 1\n",
    "    # While the video is still open, read the next frame of the video\n",
    "    while open_video.isOpened():\n",
    "        left, frame_data = open_video.read()\n",
    "\n",
    "        # Check if the frame was successfully read, if the frame is unsuccessfully read, break it\n",
    "        if not left:\n",
    "            break\n",
    "        # Else if the frame_count divide by frame wouldn't have a remainder\n",
    "        elif frame_count % frame == 0:\n",
    "            # Process the image in order to take the main object and crop it and back the background be transparent\n",
    "            img = process_img(frame_data)\n",
    "            # If the image is available\n",
    "            if img is not None and img.size != 0:\n",
    "                # Save it to the directory\n",
    "                cv2.imwrite(output_directory + '/' + f'frame{x}.png', img)\n",
    "            # Add one to the variable x\n",
    "            x += 1\n",
    "        \n",
    "        # Add one to the variable frame_count\n",
    "        frame_count += 1\n",
    "    \n",
    "    # Realease the video\n",
    "    open_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b707074a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This few example for loop is to show where we take the video of the car and take the frame of the car from the video \n",
    "# in order to collect the car image data and let us to train the model to differentiate the car type\n",
    "\n",
    "for a in range(18):\n",
    "    take_frame(f'Training Video/SEDAN/SAGA{a+1}.mov')\n",
    "    \n",
    "for b in range(19):\n",
    "    take_frame(f'Training Video/HATCHBACK/IRIZ{b+1}.mov')\n",
    "    \n",
    "for c in range(32):\n",
    "    take_frame(f'Training Video/SUV/X50{c+1}.mov')\n",
    "    \n",
    "for d in range(23):\n",
    "    take_frame(f'Training Video/SUV/X70{d+1}.mov')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fcf0c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to combine all the image of one folder which contain an amount of folder into a folder only \n",
    "def combine_file(source, destination):\n",
    "    # Set the variable x as one\n",
    "    x = 1\n",
    "    # If the path not exist\n",
    "    if not os.path.exists(destination):\n",
    "        # Make directory for the destination\n",
    "        os.makedirs(destination)\n",
    "    \n",
    "    # Loop all the folder in the directory\n",
    "    for folder in os.listdir(source):\n",
    "        # Join the filename with the directory\n",
    "        source_file = os.path.join(source, folder)\n",
    "        # Loop all the file in the folder\n",
    "        for file in os.listdir(source_file):\n",
    "            # Join the filename with the folder name\n",
    "            source_path = os.path.join(source_file, file)\n",
    "            # If the file exist\n",
    "            if os.path.isfile(source_path):\n",
    "                # Set the destination path to the destination follow by the x variable\n",
    "                destination_path = os.path.join(destination, str(x))\n",
    "                # Copy from the directory to the destination\n",
    "                shutil.copy(source_path, destination_path)\n",
    "                # Add one to the variable x\n",
    "                x += 1\n",
    "                # Rename the new file\n",
    "                new_file = os.path.splitext(destination_path)[0] + '.png'\n",
    "                os.rename(destination_path, new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2cc26a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to rotate the image of the folder with certain degree\n",
    "def rotate_images(folder_path, degrees):\n",
    "    # Loop all the file in the folder\n",
    "    for filename in os.listdir(folder_path):\n",
    "        # If the filename is end with .jpg and .png\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"): \n",
    "            # Set the variable image_path to the join of folder name and filename\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                # Open the image file\n",
    "                with Image.open(image_path) as image:\n",
    "                    # Rotate the image and save it \n",
    "                    rotated_image = image.rotate(degrees, expand=True)\n",
    "                    rotated_image.save(image_path)\n",
    "                    print(f\"Rotated {filename} successfully.\")\n",
    "            # If fail to open, print Failed to rotate in the console\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to rotate {filename}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bf668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is example of combining file and rotate the image\n",
    "source = 'Training Data/HATCHBACK'\n",
    "destination = 'Training Data/SUV'\n",
    "combine_file(source, destination)\n",
    "rotate_images('Template Photo', 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9975f913",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60/60 [==============================] - 30s 495ms/step - loss: 1.0492 - accuracy: 0.5042 - val_loss: 0.7868 - val_accuracy: 0.6635\n",
      "Epoch 2/10\n",
      "60/60 [==============================] - 30s 492ms/step - loss: 0.7253 - accuracy: 0.6928 - val_loss: 0.6041 - val_accuracy: 0.7488\n",
      "Epoch 3/10\n",
      "60/60 [==============================] - 29s 491ms/step - loss: 0.4478 - accuracy: 0.8288 - val_loss: 0.4273 - val_accuracy: 0.8294\n",
      "Epoch 4/10\n",
      "60/60 [==============================] - 29s 484ms/step - loss: 0.3000 - accuracy: 0.8867 - val_loss: 0.3984 - val_accuracy: 0.8531\n",
      "Epoch 5/10\n",
      "60/60 [==============================] - 28s 474ms/step - loss: 0.2444 - accuracy: 0.9078 - val_loss: 0.3019 - val_accuracy: 0.8720\n",
      "Epoch 6/10\n",
      "60/60 [==============================] - 28s 463ms/step - loss: 0.1272 - accuracy: 0.9557 - val_loss: 0.3610 - val_accuracy: 0.8483\n",
      "Epoch 7/10\n",
      "60/60 [==============================] - 28s 462ms/step - loss: 0.0599 - accuracy: 0.9821 - val_loss: 0.2904 - val_accuracy: 0.9194\n",
      "Epoch 8/10\n",
      "60/60 [==============================] - 28s 461ms/step - loss: 0.0311 - accuracy: 0.9884 - val_loss: 0.3881 - val_accuracy: 0.8910\n",
      "Epoch 9/10\n",
      "60/60 [==============================] - 28s 461ms/step - loss: 0.0145 - accuracy: 0.9963 - val_loss: 0.2910 - val_accuracy: 0.9147\n",
      "Epoch 10/10\n",
      "60/60 [==============================] - 28s 461ms/step - loss: 0.0181 - accuracy: 0.9953 - val_loss: 0.3046 - val_accuracy: 0.9147\n",
      "7/7 [==============================] - 1s 86ms/step - loss: 0.3046 - accuracy: 0.9147\n",
      "Loss : 0.30462393164634705, Accuracy : 0.9146919250488281\n"
     ]
    }
   ],
   "source": [
    "# Define the path to the directory which contain the car images which need to use for training\n",
    "data_dir = 'Training Data'\n",
    "\n",
    "# Define the car models in an array\n",
    "car_models = ['HATCHBACK', 'SEDAN', 'SUV']\n",
    "\n",
    "# Initialize empty lists to store the image data and labels\n",
    "images = []\n",
    "labels = []\n",
    "\n",
    "# Define the input image dimensions\n",
    "input_shape = (128, 128, 1)  # Assuming color images\n",
    "\n",
    "# Loop every item in the car_models array\n",
    "for car_model in car_models:\n",
    "    # Join the directory with the car_model item to be the new path\n",
    "    part_dir = os.path.join(data_dir, car_model)\n",
    "    # Loop the file in the car model item\n",
    "    for image_file in os.listdir(part_dir):\n",
    "        # Set the image_path by joining the file directory with the name of the image file\n",
    "        image_path = os.path.join(part_dir, image_file)\n",
    "        # Read the image\n",
    "        image = cv2.imread(image_path)\n",
    "        # If the image is available\n",
    "        if image is not None:\n",
    "            # Resize the image to a fixed size\n",
    "            image = cv2.resize(image, input_shape[:2])\n",
    "            # Convert the image from RGB to Grayscale\n",
    "            image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "            # Append the image into the image array and append the car model into the labels array\n",
    "            images.append(image)\n",
    "            labels.append(car_model)\n",
    "            \n",
    "# Convert the image and label lists to numpy arrays\n",
    "X = np.array(images)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Create a label map dictionary that map each label in the car_models list to the corresponding index\n",
    "num_classes = len(car_models)\n",
    "label_map = {label: index for index, label in enumerate(car_models)}\n",
    "\n",
    "# Convert array y of labels to an array corresponding to indices based on the provided label_map\n",
    "y = np.array([label_map[label] for label in y])\n",
    "\n",
    "# Shuffle the data\n",
    "shuffle_indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(shuffle_indices)\n",
    "X = X[shuffle_indices]\n",
    "y = y[shuffle_indices]\n",
    "\n",
    "# Split the data into 90 percent training and 10 percent testing sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n",
    "\n",
    "# Normalize pixel values\n",
    "X_train = X_train.astype('float32') / 255.0\n",
    "X_test = X_test.astype('float32') / 255.0\n",
    "\n",
    "# Reshape the input data to match the input shape of the model\n",
    "X_train = np.reshape(X_train, (-1,) + input_shape)\n",
    "X_test = np.reshape(X_test, (-1,) + input_shape)\n",
    "\n",
    "# Create a CNN model\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (3, 3), activation='relu', input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model with adam optimizer and loss function is using sparse_categorical_crossentropy\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Print the loss and accuracy of the model\n",
    "print(f'Loss : {loss}, Accuracy : {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b26aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is same as the above function name process_img.\n",
    "# Both of the function doing the same thing but with different number of input parameter.\n",
    "def process_img_path(image, a):\n",
    "    # Read the given image using cv2\n",
    "    image = cv2.imread(image)\n",
    "    # Preprocess image into a PyTorch tensor\n",
    "    transform = T.Compose([T.ToTensor()])\n",
    "    input_image = transform(image)\n",
    "    \n",
    "    # Load the pre-trained model Mask R-CNN model with a ResNet-50 backbone and FPN(Feature Pyramid Network)\n",
    "    model = maskrcnn_resnet50_fpn(pretrained=True)\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "\n",
    "    # Disable the gradient computation and use the model to predict the input image\n",
    "    with torch.no_grad():\n",
    "        predictions = model([input_image])\n",
    "        \n",
    "    # Extract the masks and boxes from the prediction and return them as a numpy array\n",
    "    masks = predictions[0]['masks'].cpu().numpy()\n",
    "    boxes = predictions[0]['boxes'].cpu().numpy()\n",
    "\n",
    "    # Calculate the areas of the boxes\n",
    "    areas = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n",
    "\n",
    "    # Find the index of largest value in the areas and use boxes to select the largest area using the index found\n",
    "    main_object_index = np.argmax(areas)\n",
    "    main_object_box = boxes[main_object_index]\n",
    "\n",
    "    # Convert the box coordinates to integers\n",
    "    main_object_box = main_object_box.astype(int)\n",
    "\n",
    "    # Extract the coordinates of the box\n",
    "    x, y, w, h = main_object_box\n",
    "\n",
    "    # Create a binary mask for the main object\n",
    "    main_object_mask = masks[main_object_index, 0] > 0.5\n",
    "\n",
    "    # Apply the binary mask to the input image\n",
    "    result = cv2.bitwise_and(image, image, mask=main_object_mask.astype(np.uint8))\n",
    "\n",
    "    # Create a background with transparent \n",
    "    transparent_background = np.zeros_like(image)\n",
    "\n",
    "    # Replace the object background as transparent \n",
    "    result[np.where(main_object_mask == 0)] = transparent_background[np.where(main_object_mask == 0)]\n",
    "\n",
    "    # Convert the result from BGR into BGRA format to make sure that the background is transparent\n",
    "    result_with_transparency = cv2.cvtColor(result, cv2.COLOR_BGR2BGRA)\n",
    "    result_with_transparency[np.where((result == [0, 0, 0]).all(axis=2))] = [0, 0, 0, 0]\n",
    "\n",
    "    # Find the contours of the object\n",
    "    contours, _ = cv2.findContours(main_object_mask.astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # Find the minimum area rectangle around the contours and convert to integer\n",
    "    rect = cv2.minAreaRect(contours[0])\n",
    "    box = cv2.boxPoints(rect).astype(np.int32)\n",
    "\n",
    "    # Crop the image using the box\n",
    "    x, y, w, h = cv2.boundingRect(box)\n",
    "    cropped_image = result_with_transparency[y:y+h, x:x+w]\n",
    "    \n",
    "    # If the image is available, save it \n",
    "    if cropped_image is not None and cropped_image.size > 0:\n",
    "       cv2.imwrite(f'ans{a}.png', cropped_image)\n",
    "    # Or else use a black image to replce it and save it\n",
    "    else:\n",
    "       cv2.imwrite(f'ans{a}.png', cv2.imread('Error Image.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c01bdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is to detect whether the image contains car to prevent wrong prediction \n",
    "def image_detect(image_path, x):\n",
    "    # The correct_num variable is set to zero and it is use to count the number of image detected car\n",
    "    correct_num = 0\n",
    "    # Load and read the template image of the car using cv2\n",
    "    template1 = cv2.imread('Template Photo/template1.png', cv2.IMREAD_GRAYSCALE)\n",
    "    template2 = cv2.imread('Template Photo/template2.png', cv2.IMREAD_GRAYSCALE)\n",
    "    template3 = cv2.imread('Template Photo/template3.png', cv2.IMREAD_GRAYSCALE)\n",
    "    template4 = cv2.imread('Template Photo/template4.png', cv2.IMREAD_GRAYSCALE)\n",
    "    template5 = cv2.imread('Template Photo/template5.png', cv2.IMREAD_GRAYSCALE)\n",
    "    template6 = cv2.imread('Template Photo/template6.png', cv2.IMREAD_GRAYSCALE)\n",
    "    template7 = cv2.imread('Template Photo/template7.png', cv2.IMREAD_GRAYSCALE)\n",
    "    template8 = cv2.imread('Template Photo/template8.png', cv2.IMREAD_GRAYSCALE)\n",
    "    template9 = cv2.imread('Template Photo/template9.png', cv2.IMREAD_GRAYSCALE)\n",
    "    template10 = cv2.imread('Template Photo/template10.png', cv2.IMREAD_GRAYSCALE)\n",
    "    template11 = cv2.imread('Template Photo/template11.png', cv2.IMREAD_GRAYSCALE)\n",
    "    template12 = cv2.imread('Template Photo/template12.png', cv2.IMREAD_GRAYSCALE)\n",
    "    # Set up an array to put in all the template of the car\n",
    "    template = [template1, template2, template3, template4, template5, template6, template7, template8, template9, template10, template11, template12]\n",
    "    \n",
    "    # Read and process the input image and save it\n",
    "    input_image = process_img_path(image_path, x)\n",
    "    input_image = cv2.imread(f\"ans{x}.png\", cv2.IMREAD_GRAYSCALE)\n",
    "    \n",
    "    # Loop all the template \n",
    "    for x in range(12):\n",
    "        # Calculate the ratio of width and height of the template image compare to the input image\n",
    "        ratio_width =  template[x].shape[1] / input_image.shape[1]\n",
    "        ratio_height = template[x].shape[0] / input_image.shape[0]\n",
    "        # Convert the template image into the similar size of the input image\n",
    "        if ratio_width > ratio_height:\n",
    "            template[x] = cv2.resize(template[x], (int(template[x].shape[1]/(ratio_width+0.01)), int(template[x].shape[0]/(ratio_width+0.01))))\n",
    "        elif ratio_width < ratio_height:\n",
    "            template[x] = cv2.resize(template[x], (int(template[x].shape[1]/(ratio_height+0.01)), int(template[x].shape[0]/(ratio_height+0.01))))\n",
    "    \n",
    "    # Loop all the input image with the template image\n",
    "    for i in range(12):\n",
    "        # If the input image shape is larger than 200x200\n",
    "        if input_image.shape[1] > 200 and input_image.shape[0] > 200:\n",
    "            # Use cv2 to match the template image and input image and put the result into the result variable\n",
    "            result = cv2.matchTemplate(input_image, template[i], cv2.TM_CCOEFF_NORMED)\n",
    "            # Set the threshold to 0.4\n",
    "            threshold = 0.4  \n",
    "            # Find indices of element which is greater than threshold\n",
    "            locations = np.where(result >= threshold)\n",
    "\n",
    "            # If any match is found above the threshold, consider it as a car\n",
    "            if len(locations[0]) > 0:\n",
    "                correct_num += 1\n",
    "    # return the correct number of predict\n",
    "    return correct_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82250a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This car_models array and input shape need to define if the model is only load from the previous pretrained model.\n",
    "# No need to initialize if the model is trained before running this code\n",
    "car_models = ['HATCHBACK', 'SEDAN', 'SUV']\n",
    "input_shape = (128, 128, 1)\n",
    "\n",
    "# This function is to predict the image of the car is in what category\n",
    "def classify_image(image_path):\n",
    "    # Read the image\n",
    "    image = cv2.imread(image_path)\n",
    "    # If the image is available\n",
    "    if image is not None:\n",
    "        # Resize the image to match the input shape of the model\n",
    "        image = cv2.resize(image, input_shape[:2])\n",
    "        # Convert the image from RGB to Grayscale\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "        # Normalize the pixel values\n",
    "        image = image.astype('float32') / 255.0\n",
    "        # Reshape the image to match the input shape of the model\n",
    "        image = np.reshape(image, (1,) + input_shape)\n",
    "        # Make prediction using the train model above to using the pretrained model\n",
    "        predictions = model.predict(image)\n",
    "        # Get the predicted class index\n",
    "        predicted_class_index = np.argmax(predictions[0])\n",
    "        # Get the corresponding car model labels\n",
    "        car_model_labels = [car_models[i] for i in range(len(car_models))]\n",
    "        # Get the percentages of matching of input image car with the predicted car\n",
    "        percentages = predictions[0] * 100\n",
    "        # If the precentage is larger than 50, then predict the car model and display the result in the console\n",
    "        if percentages[predicted_class_index] >= 50:\n",
    "            print(\"Matched: {} ({}% confidence)\".format(car_model_labels[predicted_class_index], percentages[predicted_class_index]))\n",
    "            return percentages[0], percentages[1], percentages[2]\n",
    "        # Else the car is not match to any model\n",
    "        else:\n",
    "            print(\"Not matched\")\n",
    "\n",
    "        # Display the distribution of similarities\n",
    "        for i in range(len(car_models)):\n",
    "            print(\"{}: {}%\".format(car_model_labels[i], percentages[i]))\n",
    "    # If the image is not available, print invalid image\n",
    "    else:\n",
    "        print(\"Invalid image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ef74003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is use to predict whether the four image can conclude what type of the car is\n",
    "def predict(image_path_arr):\n",
    "    # Set up the array sum_car to zero at the beginning, it is use to put the sum of percentage each category of the car  \n",
    "    sum_car = [0, 0, 0]\n",
    "    # Define the car category\n",
    "    car_category = ['hatchback', 'sedan', 'suv']\n",
    "    # Loop all the image \n",
    "    for i in range(len(image_path_arr)):\n",
    "        # Set the variable hatchback, sedan and suv as zero \n",
    "        hatchback = 0\n",
    "        sedan = 0\n",
    "        suv = 0\n",
    "        image_path = image_path_arr[i]\n",
    "        # Classify the input image car is which category\n",
    "        hatchback, sedan, suv = classify_image(image_path)\n",
    "        # Add the percentage into the sum_car variable\n",
    "        sum_car[0] += hatchback\n",
    "        sum_car[1] += sedan\n",
    "        sum_car[2] += suv\n",
    "        print(f'hatchback: {hatchback}, sedan: {sedan}, suv: {suv}')            \n",
    "    \n",
    "    # Find the max percentage of the three car category\n",
    "    max_percentage = sum_car[0]\n",
    "    car_index = 0\n",
    "    for x in range(2):\n",
    "        if sum_car[x+1] > max_percentage:\n",
    "            max_percentage = sum_car[x+1]\n",
    "            car_index = x+1\n",
    "    \n",
    "    # If the largest percentage divide by 4 is larger than 50, then predict which car category and show the percentage of confidence\n",
    "    if max_percentage/4 > 50:\n",
    "        print(f'Predicted car : {car_category[car_index]}, Predicted Percentage : {max_percentage/4}')\n",
    "    # Else the image had to be retake in order to predict the car more accurate\n",
    "    else:\n",
    "        print(\"The image is not enough to prove the car model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1df61e16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This function is use to predict the car using the four input image\n",
    "# It is first predict whether the image had car. If the image contain car then only it will predict which category the car is in\n",
    "def predict_car_category(image_path):\n",
    "    # Define the sum_num to zero, it is use to see the four input image had match to how many template image that contain car\n",
    "    sum_num = 0\n",
    "    # Loop all the input image\n",
    "    for i in range(len(image_path)):\n",
    "        # Compute the number of the image that detected car\n",
    "        num = image_detect(image_path[i], i+1)\n",
    "        sum_num += num\n",
    "    \n",
    "    # If the total of detected image is larger than 5, then only the model will predict the car category\n",
    "    if sum_num > 5:\n",
    "        predict(['ans1.png',\n",
    "                 'ans2.png',\n",
    "                 'ans3.png',\n",
    "                 'ans4.png'])\n",
    "    # Or else the image had to be retake in order to predict the car category\n",
    "    else:\n",
    "        print(\"Input images were incompatible with car classification model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df028207",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is to save the model after the model had been train in order to use it to predict the car category in future\n",
    "model.save('model128_64_128_128_128.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "30d962c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved pretrained model\n",
    "model = load_model('model128_64_128_128_128.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7090572e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step\n",
      "Matched: HATCHBACK (99.4267578125% confidence)\n",
      "hatchback: 99.4267578125, sedan: 0.004365134984254837, suv: 0.5688737630844116\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Matched: SEDAN (83.45654296875% confidence)\n",
      "hatchback: 0.007198809180408716, sedan: 83.45654296875, suv: 16.5362548828125\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Matched: HATCHBACK (97.55409240722656% confidence)\n",
      "hatchback: 97.55409240722656, sedan: 2.305206775665283, suv: 0.14070414006710052\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "Matched: HATCHBACK (98.9119644165039% confidence)\n",
      "hatchback: 98.9119644165039, sedan: 0.0001395588624291122, suv: 1.0878931283950806\n",
      "Predicted car : hatchback, Predicted Percentage : 73.97500336135272\n"
     ]
    }
   ],
   "source": [
    "# This is an example of predicting car category\n",
    "predict_car_category(['Testing Data/AXIA LEFT SIDE.jpg',\n",
    "                      'Testing Data/AXIA FRONT.jpg',\n",
    "                      'Testing Data/AXIA BACK.jpg',\n",
    "                      'Testing Data/AXIA RIGHT SIDE.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbd8fce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "Matched: SUV (99.9999771118164% confidence)\n",
      "hatchback: 2.822132591973059e-05, sedan: 1.3013168320696877e-08, suv: 99.9999771118164\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Matched: SEDAN (96.63973999023438% confidence)\n",
      "hatchback: 0.47029909491539, sedan: 96.63973999023438, suv: 2.8899638652801514\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Matched: SEDAN (99.89816284179688% confidence)\n",
      "hatchback: 0.0007564264233224094, sedan: 99.89816284179688, suv: 0.10106825828552246\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "Matched: SUV (99.99995422363281% confidence)\n",
      "hatchback: 9.922285926222685e-07, sedan: 4.157980583840981e-05, suv: 99.99995422363281\n",
      "Predicted car : suv, Predicted Percentage : 50.74774086475372\n"
     ]
    }
   ],
   "source": [
    "# This is an example of predicting car category\n",
    "predict_car_category(['Testing Data/CRV LEFT SIDE.jpg',\n",
    "                      'Testing Data/CRV FRONT.jpg',\n",
    "                      'Testing Data/CRV BACK.jpg',\n",
    "                      'Testing Data/CRV RIGHT SIDE.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "938797ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step\n",
      "Matched: SUV (99.47535705566406% confidence)\n",
      "hatchback: 0.009767252951860428, sedan: 0.5148714184761047, suv: 99.47535705566406\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Matched: HATCHBACK (96.7442855834961% confidence)\n",
      "hatchback: 96.7442855834961, sedan: 1.3586804866790771, suv: 1.8970277309417725\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Matched: HATCHBACK (99.62906646728516% confidence)\n",
      "hatchback: 99.62906646728516, sedan: 0.26631852984428406, suv: 0.10461023449897766\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Matched: HATCHBACK (55.693416595458984% confidence)\n",
      "hatchback: 55.693416595458984, sedan: 44.28823471069336, suv: 0.0183410681784153\n",
      "Predicted car : hatchback, Predicted Percentage : 63.019133974798024\n"
     ]
    }
   ],
   "source": [
    "# This is an example of predicting car category\n",
    "predict_car_category(['Testing Data/GRAND LEFT SIDE.jpg',\n",
    "                      'Testing Data/GRAND FRONT.jpg',\n",
    "                      'Testing Data/GRAND BACK.jpg',\n",
    "                      'Testing Data/GRAND RIGHT SIDE.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "63bab033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 29ms/step\n",
      "Matched: HATCHBACK (64.30679321289062% confidence)\n",
      "hatchback: 64.30679321289062, sedan: 35.52077865600586, suv: 0.17242205142974854\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Matched: SEDAN (99.99774932861328% confidence)\n",
      "hatchback: 0.0022515878081321716, sedan: 99.99774932861328, suv: 7.442391165568552e-07\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "Matched: SUV (80.10796356201172% confidence)\n",
      "hatchback: 0.18735335767269135, sedan: 19.70467758178711, suv: 80.10796356201172\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Matched: SUV (61.9642448425293% confidence)\n",
      "hatchback: 9.072932243347168, sedan: 28.962820053100586, suv: 61.9642448425293\n",
      "The image is not enough to prove the car model.\n"
     ]
    }
   ],
   "source": [
    "# This is an example of predicting car category\n",
    "predict_car_category(['Testing Data/KELISA LEFT SIDE.jpg',\n",
    "                      'Testing Data/KELISA FRONT.jpg',\n",
    "                      'Testing Data/KELISA BACK.jpg',\n",
    "                      'Testing Data/KELISA RIGHT SIDE.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "10382e8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "Matched: SEDAN (93.58775329589844% confidence)\n",
      "hatchback: 6.410701751708984, sedan: 93.58775329589844, suv: 0.0015553187113255262\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Matched: SUV (98.82181549072266% confidence)\n",
      "hatchback: 1.1781058311462402, sedan: 7.992513565113768e-05, suv: 98.82181549072266\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "Matched: SEDAN (85.68953704833984% confidence)\n",
      "hatchback: 0.000276043894700706, sedan: 85.68953704833984, suv: 14.310185432434082\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Matched: SEDAN (99.83934783935547% confidence)\n",
      "hatchback: 0.16063249111175537, sedan: 99.83934783935547, suv: 1.0119579201273154e-05\n",
      "Predicted car : sedan, Predicted Percentage : 69.77917952718235\n"
     ]
    }
   ],
   "source": [
    "# This is an example of predicting car category\n",
    "predict_car_category(['Testing Data/VIOS LEFT SIDE.jpg',\n",
    "                      'Testing Data/VIOS FRONT.jpg',\n",
    "                      'Testing Data/VIOS BACK.jpg',\n",
    "                      'Testing Data/VIOS RIGHT SIDE.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cf11734",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input images were incompatible with car classification model\n"
     ]
    }
   ],
   "source": [
    "# This is an example of predicting car category\n",
    "predict_car_category(['Testing Data/CAT SIDE.jpg',\n",
    "                      'Testing Data/CAT FRONT.jpg',\n",
    "                      'Testing Data/CAT BACK.jpg',\n",
    "                      'Testing Data/CAT SIDE2.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ff6904",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
